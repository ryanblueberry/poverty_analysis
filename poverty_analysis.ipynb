{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://urldefense.com/v3/__https://localhost:8080/__;!!Mih3wA!B14CyWPRDqkcCvQ7hvNsKmTyevDD2x1iJ_njKMCLQ_aOukCKCnrUvDbR4GD60DqBko1kwoXZpuW62lgNgiAl$ "
    },
    "id": "KjuDZavIz3P4",
    "outputId": "f2172ec1-fdd1-4457-efa2-e402fe8fffc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:159: UserWarning: pylab import has clobbered these variables: ['mean', 'std']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "VpmuGQKJZaGq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/obaid/Desktop/bigdata/anon_images\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "path = 'C:/Users/obaid/Desktop/bigdata/anon_images'\n",
    "        \n",
    "band_names=['Red','Green','Blue','NIR','SWIR1','SWIR2','TEMP1','NL']\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://urldefense.com/v3/__https://localhost:8080/__;!!Mih3wA!B14CyWPRDqkcCvQ7hvNsKmTyevDD2x1iJ_njKMCLQ_aOukCKCnrUvDbR4GD60DqBko1kwoXZpuW62lgNgiAl$ "
    },
    "id": "wZVqPX9JZbOD",
    "outputId": "fcd3c7d1-efc8-4024-f911-beb1b04ec12a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19669"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = 'C:/Users/obaid/Desktop/bigdata/anon_images'\n",
    "files = glob(os.path.join(files, '*'))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://urldefense.com/v3/__https://localhost:8080/__;!!Mih3wA!B14CyWPRDqkcCvQ7hvNsKmTyevDD2x1iJ_njKMCLQ_aOukCKCnrUvDbR4GD60DqBko1kwoXZpuW62lgNgiAl$ ",
     "height": 174
    },
    "id": "jiXpyFeb0ZyB",
    "outputId": "ccf79948-8b89-4130-b599-0b908ffd3da2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>country</th>\n",
       "      <th>wealthpooled</th>\n",
       "      <th>urban</th>\n",
       "      <th>label</th>\n",
       "      <th>nl_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filename</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>image13724.npz</th>\n",
       "      <td>image13724.npz</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.090052</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.097684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image7407.npz</th>\n",
       "      <td>image7407.npz</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.143002</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.141589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image390.npz</th>\n",
       "      <td>image390.npz</td>\n",
       "      <td>6</td>\n",
       "      <td>1.056769</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>15.228898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      filename  country  wealthpooled  urban  label    nl_mean\n",
       "filename                                                                      \n",
       "image13724.npz  image13724.npz        6     -1.090052  False      0  -0.097684\n",
       "image7407.npz    image7407.npz        6     -1.143002  False      0  -0.141589\n",
       "image390.npz      image390.npz        6      1.056769   True      0  15.228898"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load table entries\n",
    "train_table = r'https://raw.githubusercontent.com/SateeshKumar21/PovertyAnalysis/Vocareum/HW5/public_tables/train.csv__;!!Mih3wA!B14CyWPRDqkcCvQ7hvNsKmTyevDD2x1iJ_njKMCLQ_aOukCKCnrUvDbR4GD60DqBko1kwoXZpuW62tQHdsHD$ ' \n",
    "#!ls -l $train_table\n",
    "\n",
    "df=pd.read_csv(train_table,index_col=0)\n",
    "df.index=df['filename']\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://urldefense.com/v3/__https://localhost:8080/__;!!Mih3wA!B14CyWPRDqkcCvQ7hvNsKmTyevDD2x1iJ_njKMCLQ_aOukCKCnrUvDbR4GD60DqBko1kwoXZpuW62lgNgiAl$ "
    },
    "id": "wWDQqdbSGRSs",
    "outputId": "5392e9d3-aca2-4f29-bf3b-d7a358a1d32c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11288"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "Pg5BFDXK0bEu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 113.27044248580933 seconds\n",
      "0\n",
      "float type error: None\n",
      "length of file 11288\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time=time.time()\n",
    "channel_values_lis = []\n",
    "\n",
    "floattypeerror=0\n",
    "# change the range to load more data, I picked 5000 bc that creates ~4.2 GiBs to download\n",
    "for n in range(11288):\n",
    "\n",
    "    row=df.iloc[n,:]\n",
    "    filename=row['filename']\n",
    "    urban=row['urban']\n",
    "    area ='urban' if urban else 'rural'\n",
    "    try:\n",
    "        M=load(path+'/'+filename)\n",
    "    except:\n",
    "        print (f'could not load image:{n}, path:'+path+\"/\"+filename)\n",
    "        continue\n",
    "    Image=M['x']\n",
    "    if np.max(Image) > 65_536:\n",
    "        print(\"above 16 byte size\")\n",
    "        channel_values_lis.append(Image)\n",
    "        floattypeerror+=1\n",
    "    elif np.max(Image) < -65_536:\n",
    "        print(\"below 16 byte size\")\n",
    "        channel_values_lis.append(Image)\n",
    "        floattypeerror+=1\n",
    "    else:\n",
    "        recast_arr = Image.astype(np.float16)\n",
    "        channel_values_lis.append(recast_arr)\n",
    "        \n",
    "\n",
    "end_time= time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(\"Execution time:\", execution_time,\"seconds\")\n",
    "print(\"float type error:\", print(floattypeerror))\n",
    "print(\"length of file\", len(channel_values_lis))\n",
    "# uncomment to cave file\n",
    "# np.save('channel_values_lis.npy', np.array(channel_values_lis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "r-2hzmhgF7or"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11288"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(channel_values_lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "S1qLo3oC4Bc1"
   },
   "outputs": [],
   "source": [
    "column_names=[\"Red\", \"Green\", \"Blue\", \"NIR\", \"SWIR1\", \"SWIR2\", \"TEMP1\", \"NL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "-ghOdXh64Bc2"
   },
   "outputs": [],
   "source": [
    "#input image features into dataframe\n",
    "for column in range(len(column_names)):\n",
    "    lis = []\n",
    "    for n in range(len(channel_values_lis)):\n",
    "        lis.append(channel_values_lis[n][column])\n",
    "    df[column_names[column]] = lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "4ILCqL2H1Hxx"
   },
   "outputs": [],
   "source": [
    "#mean\n",
    "for column in range(len(column_names)):\n",
    "    lis = []\n",
    "    for n in range(len(channel_values_lis)):\n",
    "        lis.append(channel_values_lis[n][column].mean())\n",
    "    df[column_names[column] + '_mean'] = lis\n",
    "\n",
    "#std\n",
    "for column in range(len(column_names)):\n",
    "    lis = []\n",
    "    for n in range(len(channel_values_lis)):\n",
    "        lis.append(np.std(channel_values_lis[n][column], dtype = np.float64))\n",
    "    df[column_names[column] + '_std'] = lis\n",
    "\n",
    "#median\n",
    "for column in range(len(column_names)):\n",
    "    lis = []\n",
    "    for n in range(len(channel_values_lis)):\n",
    "        lis.append(np.median(channel_values_lis[n][column]))\n",
    "    df[column_names[column] + '_median'] = lis\n",
    "\n",
    "#bright outliers\n",
    "for column in range(len(column_names)):\n",
    "    lis = []\n",
    "    for n in range(len(channel_values_lis)):\n",
    "        mean_col = column_names[column] + '_mean'\n",
    "        std_col = column_names[column] + '_std'\n",
    "        mean = df.iloc[n][mean_col]\n",
    "        std = df.iloc[n][std_col]\n",
    "        lis.append(np.count_nonzero(channel_values_lis[n][column] > (mean + 1.5 * std)))\n",
    "    df[column_names[column] + '_br_outlier'] = lis\n",
    "\n",
    "#dark outlier\n",
    "for column in range(len(column_names)):\n",
    "    lis = []\n",
    "    for n in range(len(channel_values_lis)):\n",
    "        mean_col = column_names[column] + '_mean'\n",
    "        std_col = column_names[column] + '_std'\n",
    "        mean = df.iloc[n][mean_col]\n",
    "        std = df.iloc[n][std_col]\n",
    "        lis.append(np.count_nonzero(channel_values_lis[n][column] < (mean - 1.5 * std)))\n",
    "    df[column_names[column] + '_dark_outlier'] = lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "Xebvr0QE8RiL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urban_df_labels shape (4020, 2)\n",
      "rural_df_labels shape (7268, 2)\n",
      " \n",
      "urban_df_features shape (4020, 52)\n",
      "rural_df_features shape (7268, 52)\n",
      "Urban train shape: (3618, 42) (3618,)\n",
      "Urban validation shape: (402, 42) (402,)\n",
      "Rural train shape: (6541, 42) (6541,)\n",
      "Rural validation shape: (727, 42) (727,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\AppData\\Local\\Temp\\ipykernel_22788\\1429553098.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://urldefense.com/v3/__https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html*returning-a-view-versus-a-copy*5Cn__;IyU!!Mih3wA!B14CyWPRDqkcCvQ7hvNsKmTyevDD2x1iJ_njKMCLQ_aOukCKCnrUvDbR4GD60DqBko1kwoXZpuW62itULFX1$   urban_df_labels.loc[:, 'wealthpooled'] = urban_df_labels['wealthpooled'].astype('float32')\n",
      "C:\\Users\\obaid\\AppData\\Local\\Temp\\ipykernel_22788\\1429553098.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://urldefense.com/v3/__https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html*returning-a-view-versus-a-copy*5Cn__;IyU!!Mih3wA!B14CyWPRDqkcCvQ7hvNsKmTyevDD2x1iJ_njKMCLQ_aOukCKCnrUvDbR4GD60DqBko1kwoXZpuW62itULFX1$   rural_df_labels.loc[:, 'wealthpooled'] = rural_df_labels['wealthpooled'].astype('float32')\n"
     ]
    }
   ],
   "source": [
    "urban_df = df[df['urban']==True]\n",
    "rural_df = df[df['urban'] ==False]\n",
    "urban_df_labels = urban_df[['wealthpooled', 'label']]\n",
    "rural_df_labels = rural_df[['wealthpooled', 'label']]\n",
    "urban_df_features = urban_df.drop(columns=[\"wealthpooled\", \"label\"])\n",
    "rural_df_features = rural_df.drop(columns=[\"wealthpooled\", \"label\"])\n",
    "\n",
    "print(\"urban_df_labels shape\", urban_df_labels.shape)\n",
    "print(\"rural_df_labels shape\", rural_df_labels.shape)\n",
    "print(\" \")\n",
    "print(\"urban_df_features shape\", urban_df_features.shape)\n",
    "print(\"rural_df_features shape\", rural_df_features.shape)\n",
    "######################\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#remove columns with the string values\n",
    "numeric_columns = urban_df_features.select_dtypes(include=np.number).columns\n",
    "urban_df_features_numeric = urban_df_features[numeric_columns]\n",
    "\n",
    "#convert target variables\n",
    "urban_df_labels.loc[:, 'wealthpooled'] = urban_df_labels['wealthpooled'].astype('float32')\n",
    "\n",
    "#train-test split(urban data)\n",
    "urban_X_train, urban_X_val, urban_y_train, urban_y_val = train_test_split(\n",
    "    urban_df_features_numeric.values.astype('float32'),\n",
    "    urban_df_labels['wealthpooled'].values,\n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# #train-validation split (urban data)\n",
    "#urban_X_train, urban_X_val, urban_y_train, urban_y_val = train_test_split(\n",
    "#     urban_X_train,\n",
    "#     urban_y_train,\n",
    "#     test_size=0.11111,\n",
    "#    random_state=42\n",
    "#)\n",
    "\n",
    "#remove columns with string values\n",
    "numeric_columns = rural_df_features.select_dtypes(include=np.number).columns\n",
    "rural_df_features_numeric = rural_df_features[numeric_columns]\n",
    "\n",
    "#convert target variables\n",
    "rural_df_labels.loc[:, 'wealthpooled'] = rural_df_labels['wealthpooled'].astype('float32')\n",
    "\n",
    "#train-test split (rural data)\n",
    "rural_X_train, rural_X_val, rural_y_train, rural_y_val = train_test_split(\n",
    "    rural_df_features_numeric.values.astype('float32'),\n",
    "    rural_df_labels['wealthpooled'].values,\n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# #train-validation split for rural data\n",
    "#rural_X_train, rural_X_val, rural_y_train, rural_y_val = train_test_split(\n",
    "#     rural_X_train,\n",
    "#     rural_y_train,\n",
    "#     test_size=0.111111,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "print(\"Urban train shape:\", urban_X_train.shape, urban_y_train.shape)\n",
    "print(\"Urban validation shape:\", urban_X_val.shape, urban_y_val.shape)\n",
    "#print(\"Urban test shape:\", urban_X_test.shape, urban_y_test.shape)\n",
    "print(\"Rural train shape:\", rural_X_train.shape, rural_y_train.shape)\n",
    "print(\"Rural validation shape:\", rural_X_val.shape, rural_y_val.shape)\n",
    "#print(\"Rural test shape:\", rural_X_test.shape, rural_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "xKFGlplQ1ah8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "57/57 [==============================] - 1s 4ms/step - loss: 0.6162 - accuracy: 0.6559 - val_loss: 0.5539 - val_accuracy: 0.7114\n",
      "Epoch 2/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7255 - val_loss: 0.5238 - val_accuracy: 0.7264\n",
      "Epoch 3/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.7449 - val_loss: 0.5105 - val_accuracy: 0.7164\n",
      "Epoch 4/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7535 - val_loss: 0.5004 - val_accuracy: 0.7338\n",
      "Epoch 5/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7629 - val_loss: 0.4930 - val_accuracy: 0.7289\n",
      "Epoch 6/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7764 - val_loss: 0.4941 - val_accuracy: 0.7388\n",
      "Epoch 7/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7778 - val_loss: 0.4898 - val_accuracy: 0.7388\n",
      "Epoch 8/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7819 - val_loss: 0.4952 - val_accuracy: 0.7313\n",
      "Epoch 9/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7891 - val_loss: 0.4951 - val_accuracy: 0.7289\n",
      "Epoch 10/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4474 - accuracy: 0.7897 - val_loss: 0.4958 - val_accuracy: 0.7264\n",
      "Epoch 11/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4391 - accuracy: 0.7922 - val_loss: 0.4866 - val_accuracy: 0.7463\n",
      "Epoch 12/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.7941 - val_loss: 0.4823 - val_accuracy: 0.7562\n",
      "Epoch 13/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7946 - val_loss: 0.4869 - val_accuracy: 0.7438\n",
      "Epoch 14/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4243 - accuracy: 0.7955 - val_loss: 0.4809 - val_accuracy: 0.7488\n",
      "Epoch 15/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4192 - accuracy: 0.8057 - val_loss: 0.4786 - val_accuracy: 0.7512\n",
      "Epoch 16/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4140 - accuracy: 0.8076 - val_loss: 0.4819 - val_accuracy: 0.7612\n",
      "Epoch 17/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4052 - accuracy: 0.8101 - val_loss: 0.4942 - val_accuracy: 0.7612\n",
      "Epoch 18/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8085 - val_loss: 0.4988 - val_accuracy: 0.7438\n",
      "Epoch 19/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8151 - val_loss: 0.4920 - val_accuracy: 0.7662\n",
      "Epoch 20/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.8167 - val_loss: 0.4778 - val_accuracy: 0.7587\n",
      "Epoch 21/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8217 - val_loss: 0.4909 - val_accuracy: 0.7637\n",
      "Epoch 22/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8259 - val_loss: 0.4913 - val_accuracy: 0.7562\n",
      "Epoch 23/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3770 - accuracy: 0.8267 - val_loss: 0.4962 - val_accuracy: 0.7637\n",
      "Epoch 24/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8248 - val_loss: 0.4980 - val_accuracy: 0.7662\n",
      "Epoch 25/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8317 - val_loss: 0.5179 - val_accuracy: 0.7512\n",
      "Epoch 26/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3662 - accuracy: 0.8361 - val_loss: 0.5124 - val_accuracy: 0.7711\n",
      "Epoch 27/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8320 - val_loss: 0.5079 - val_accuracy: 0.7662\n",
      "Epoch 28/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8344 - val_loss: 0.4948 - val_accuracy: 0.7786\n",
      "Epoch 29/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.8391 - val_loss: 0.4988 - val_accuracy: 0.7736\n",
      "Epoch 30/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3458 - accuracy: 0.8419 - val_loss: 0.5216 - val_accuracy: 0.7736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bf95dbb730>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#normalize\n",
    "scaler = StandardScaler()\n",
    "urban_X_train_scaled = scaler.fit_transform(urban_X_train)\n",
    "urban_X_val_scaled = scaler.transform(urban_X_val)\n",
    "#urban_X_test_scaled = scaler.transform(urban_X_test)\n",
    "\n",
    "rural_X_train_scaled = scaler.fit_transform(rural_X_train)\n",
    "rural_X_val_scaled = scaler.fit_transform(rural_X_val)\n",
    "#rural_X_test_scaled = scalar.transform(rural_X_test)\n",
    "\n",
    "#convert labels\n",
    "urban_y_train_binary = (urban_y_train > 1.2).astype(int)\n",
    "urban_y_val_binary = (urban_y_val > 1.2).astype(int)\n",
    "#urban_y_test_binary = (urban_y_test > 1.2).astype(int)\n",
    "\n",
    "rural_y_train_binary = (rural_y_train > -0.5).astype(int)\n",
    "rural_y_val_binary = (rural_y_val > -0.5).astype(int)\n",
    "#rural_y_test_binary = (rural_y_test > -0.5).astype(int)\n",
    "\n",
    "######make sure I change to rural or urban\n",
    "\n",
    "urban_model = Sequential()\n",
    "urban_model.add(Dense(64, activation='relu', input_shape=(42,)))\n",
    "urban_model.add(Dense(32, activation='relu'))\n",
    "urban_model.add(Dense(16, activation='relu'))\n",
    "urban_model.add(Dense(1, activation='sigmoid'))\n",
    "urban_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#train, predict\n",
    "urban_model.fit(urban_X_train_scaled, urban_y_train_binary, batch_size=64, epochs=30, validation_data=(urban_X_val_scaled, urban_y_val_binary))\n",
    "#loss, accuracy = urban_model.evaluate(urban_X_test_scaled, urban_y_test_binary)\n",
    "#print(f\"Test Loss: {loss:.4f}\")\n",
    "#print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "#print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "CDuxSdcgV4cB",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "103/103 [==============================] - 1s 3ms/step - loss: 0.6266 - accuracy: 0.6534 - val_loss: 0.5911 - val_accuracy: 0.6933\n",
      "Epoch 2/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.5642 - accuracy: 0.7147 - val_loss: 0.5525 - val_accuracy: 0.7249\n",
      "Epoch 3/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.5391 - accuracy: 0.7312 - val_loss: 0.5494 - val_accuracy: 0.7235\n",
      "Epoch 4/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.5227 - accuracy: 0.7441 - val_loss: 0.5662 - val_accuracy: 0.7070\n",
      "Epoch 5/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.7500 - val_loss: 0.5432 - val_accuracy: 0.7331\n",
      "Epoch 6/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.5004 - accuracy: 0.7606 - val_loss: 0.5603 - val_accuracy: 0.7345\n",
      "Epoch 7/30\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7684 - val_loss: 0.5414 - val_accuracy: 0.7387\n",
      "Epoch 8/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4824 - accuracy: 0.7685 - val_loss: 0.5502 - val_accuracy: 0.7235\n",
      "Epoch 9/30\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7724 - val_loss: 0.5587 - val_accuracy: 0.7373\n",
      "Epoch 10/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7815 - val_loss: 0.5497 - val_accuracy: 0.7304\n",
      "Epoch 11/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7849 - val_loss: 0.5475 - val_accuracy: 0.7318\n",
      "Epoch 12/30\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7860 - val_loss: 0.5614 - val_accuracy: 0.7194\n",
      "Epoch 13/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7922 - val_loss: 0.5623 - val_accuracy: 0.7304\n",
      "Epoch 14/30\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4412 - accuracy: 0.7974 - val_loss: 0.5586 - val_accuracy: 0.7249\n",
      "Epoch 15/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.7968 - val_loss: 0.5856 - val_accuracy: 0.7290\n",
      "Epoch 16/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4314 - accuracy: 0.7999 - val_loss: 0.5443 - val_accuracy: 0.7565\n",
      "Epoch 17/30\n",
      "103/103 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7990 - val_loss: 0.5444 - val_accuracy: 0.7400\n",
      "Epoch 18/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4196 - accuracy: 0.8086 - val_loss: 0.5739 - val_accuracy: 0.7345\n",
      "Epoch 19/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.8063 - val_loss: 0.5719 - val_accuracy: 0.7304\n",
      "Epoch 20/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.8086 - val_loss: 0.5937 - val_accuracy: 0.7235\n",
      "Epoch 21/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4056 - accuracy: 0.8121 - val_loss: 0.5786 - val_accuracy: 0.7276\n",
      "Epoch 22/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4028 - accuracy: 0.8123 - val_loss: 0.5682 - val_accuracy: 0.7455\n",
      "Epoch 23/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.3950 - accuracy: 0.8167 - val_loss: 0.5937 - val_accuracy: 0.7249\n",
      "Epoch 24/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.3920 - accuracy: 0.8184 - val_loss: 0.5795 - val_accuracy: 0.7263\n",
      "Epoch 25/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.3864 - accuracy: 0.8231 - val_loss: 0.5861 - val_accuracy: 0.7276\n",
      "Epoch 26/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.3831 - accuracy: 0.8272 - val_loss: 0.6056 - val_accuracy: 0.7400\n",
      "Epoch 27/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.3808 - accuracy: 0.8239 - val_loss: 0.6391 - val_accuracy: 0.7235\n",
      "Epoch 28/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.3693 - accuracy: 0.8347 - val_loss: 0.5976 - val_accuracy: 0.7469\n",
      "Epoch 29/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8279 - val_loss: 0.5943 - val_accuracy: 0.7345\n",
      "Epoch 30/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.3653 - accuracy: 0.8346 - val_loss: 0.6198 - val_accuracy: 0.7373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bf6b77a940>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rural_model = Sequential()\n",
    "rural_model.add(Dense(64, activation='relu', input_shape=(42,)))\n",
    "rural_model.add(Dense(32, activation='relu'))\n",
    "rural_model.add(Dense(16, activation='relu'))\n",
    "rural_model.add(Dense(1, activation='sigmoid'))\n",
    "rural_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#train, predict\n",
    "rural_model.fit(rural_X_train_scaled, rural_y_train_binary, batch_size=64, epochs=30, validation_data=(rural_X_val_scaled, rural_y_val_binary))\n",
    "#loss, accuracy = rural_model.evaluate(rural_X_test_scaled, rural_y_test_binary)\n",
    "#print(f\"Test Loss: {loss:.4f}\")\n",
    "#print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "#print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'country', 'urban', 'nl_mean', 'Red', 'Green', 'Blue',\n",
       "       'NIR', 'SWIR1', 'SWIR2', 'TEMP1', 'NL', 'Red_mean', 'Green_mean',\n",
       "       'Blue_mean', 'NIR_mean', 'SWIR1_mean', 'SWIR2_mean', 'TEMP1_mean',\n",
       "       'NL_mean', 'Red_std', 'Green_std', 'Blue_std', 'NIR_std', 'SWIR1_std',\n",
       "       'SWIR2_std', 'TEMP1_std', 'NL_std', 'Red_median', 'Green_median',\n",
       "       'Blue_median', 'NIR_median', 'SWIR1_median', 'SWIR2_median',\n",
       "       'TEMP1_median', 'NL_median', 'Red_br_outlier', 'Green_br_outlier',\n",
       "       'Blue_br_outlier', 'NIR_br_outlier', 'SWIR1_br_outlier',\n",
       "       'SWIR2_br_outlier', 'TEMP1_br_outlier', 'NL_br_outlier',\n",
       "       'Red_dark_outlier', 'Green_dark_outlier', 'Blue_dark_outlier',\n",
       "       'NIR_dark_outlier', 'SWIR1_dark_outlier', 'SWIR2_dark_outlier',\n",
       "       'TEMP1_dark_outlier', 'NL_dark_outlier'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urban_df_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "Xebvr0QE8RiL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urban_df_labels shape (4020, 2)\n",
      "rural_df_labels shape (7268, 2)\n",
      " \n",
      "urban_df_features shape (4020, 51)\n",
      "rural_df_features shape (7268, 51)\n",
      "Urban train shape: (3618, 41) (3618,)\n",
      "Urban validation shape: (402, 41) (402,)\n",
      "Rural train shape: (6541, 41) (6541,)\n",
      "Rural validation shape: (727, 41) (727,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\AppData\\Local\\Temp\\ipykernel_22788\\440436543.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://urldefense.com/v3/__https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html*returning-a-view-versus-a-copy*5Cn__;IyU!!Mih3wA!B14CyWPRDqkcCvQ7hvNsKmTyevDD2x1iJ_njKMCLQ_aOukCKCnrUvDbR4GD60DqBko1kwoXZpuW62itULFX1$   urban_df_labels.loc[:, 'wealthpooled'] = urban_df_labels['wealthpooled'].astype('float32')\n",
      "C:\\Users\\obaid\\AppData\\Local\\Temp\\ipykernel_22788\\440436543.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://urldefense.com/v3/__https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html*returning-a-view-versus-a-copy*5Cn__;IyU!!Mih3wA!B14CyWPRDqkcCvQ7hvNsKmTyevDD2x1iJ_njKMCLQ_aOukCKCnrUvDbR4GD60DqBko1kwoXZpuW62itULFX1$   rural_df_labels.loc[:, 'wealthpooled'] = rural_df_labels['wealthpooled'].astype('float32')\n"
     ]
    }
   ],
   "source": [
    "#+without country\n",
    "urban_df = df[df['urban']==True]\n",
    "rural_df = df[df['urban'] ==False]\n",
    "urban_df_labels = urban_df[['wealthpooled', 'label']]\n",
    "rural_df_labels = rural_df[['wealthpooled', 'label']]\n",
    "\n",
    "urban_df_features = urban_df.drop(columns=[\"wealthpooled\", \"label\",\"country\"])\n",
    "rural_df_features = rural_df.drop(columns=[\"wealthpooled\", \"label\",\"country\"])\n",
    "\n",
    "print(\"urban_df_labels shape\", urban_df_labels.shape)\n",
    "print(\"rural_df_labels shape\", rural_df_labels.shape)\n",
    "print(\" \")\n",
    "print(\"urban_df_features shape\", urban_df_features.shape)\n",
    "print(\"rural_df_features shape\", rural_df_features.shape)\n",
    "######################\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#remove columns with the string values\n",
    "numeric_columns = urban_df_features.select_dtypes(include=np.number).columns\n",
    "urban_df_features_numeric = urban_df_features[numeric_columns]\n",
    "\n",
    "#convert target variables\n",
    "urban_df_labels.loc[:, 'wealthpooled'] = urban_df_labels['wealthpooled'].astype('float32')\n",
    "\n",
    "#train-test split(urban data)\n",
    "urban_X_train, urban_X_val, urban_y_train, urban_y_val = train_test_split(\n",
    "    urban_df_features_numeric.values.astype('float32'),\n",
    "    urban_df_labels['wealthpooled'].values,\n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# #train-validation split (urban data)\n",
    "#urban_X_train, urban_X_val, urban_y_train, urban_y_val = train_test_split(\n",
    "#     urban_X_train,\n",
    "#     urban_y_train,\n",
    "#     test_size=0.11111,\n",
    "#    random_state=42\n",
    "#)\n",
    "\n",
    "#remove columns with string values\n",
    "numeric_columns = rural_df_features.select_dtypes(include=np.number).columns\n",
    "rural_df_features_numeric = rural_df_features[numeric_columns]\n",
    "\n",
    "#convert target variables\n",
    "rural_df_labels.loc[:, 'wealthpooled'] = rural_df_labels['wealthpooled'].astype('float32')\n",
    "\n",
    "#train-test split (rural data)\n",
    "rural_X_train, rural_X_val, rural_y_train, rural_y_val = train_test_split(\n",
    "    rural_df_features_numeric.values.astype('float32'),\n",
    "    rural_df_labels['wealthpooled'].values,\n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# #train-validation split for rural data\n",
    "#rural_X_train, rural_X_val, rural_y_train, rural_y_val = train_test_split(\n",
    "#     rural_X_train,\n",
    "#     rural_y_train,\n",
    "#     test_size=0.111111,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "print(\"Urban train shape:\", urban_X_train.shape, urban_y_train.shape)\n",
    "print(\"Urban validation shape:\", urban_X_val.shape, urban_y_val.shape)\n",
    "#print(\"Urban test shape:\", urban_X_test.shape, urban_y_test.shape)\n",
    "print(\"Rural train shape:\", rural_X_train.shape, rural_y_train.shape)\n",
    "print(\"Rural validation shape:\", rural_X_val.shape, rural_y_val.shape)\n",
    "#print(\"Rural test shape:\", rural_X_test.shape, rural_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "xKFGlplQ1ah8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "57/57 [==============================] - 1s 3ms/step - loss: 0.5859 - accuracy: 0.6899 - val_loss: 0.5546 - val_accuracy: 0.7189\n",
      "Epoch 2/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7319 - val_loss: 0.5472 - val_accuracy: 0.6990\n",
      "Epoch 3/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.7383 - val_loss: 0.5387 - val_accuracy: 0.7114\n",
      "Epoch 4/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7479 - val_loss: 0.5346 - val_accuracy: 0.7164\n",
      "Epoch 5/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7590 - val_loss: 0.5222 - val_accuracy: 0.7338\n",
      "Epoch 6/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.7653 - val_loss: 0.5148 - val_accuracy: 0.7289\n",
      "Epoch 7/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4747 - accuracy: 0.7736 - val_loss: 0.5125 - val_accuracy: 0.7388\n",
      "Epoch 8/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7747 - val_loss: 0.5254 - val_accuracy: 0.7114\n",
      "Epoch 9/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7830 - val_loss: 0.5124 - val_accuracy: 0.7289\n",
      "Epoch 10/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.7888 - val_loss: 0.5165 - val_accuracy: 0.7413\n",
      "Epoch 11/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.7935 - val_loss: 0.5062 - val_accuracy: 0.7562\n",
      "Epoch 12/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.7933 - val_loss: 0.5076 - val_accuracy: 0.7363\n",
      "Epoch 13/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7980 - val_loss: 0.5190 - val_accuracy: 0.7338\n",
      "Epoch 14/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4213 - accuracy: 0.8010 - val_loss: 0.5247 - val_accuracy: 0.7338\n",
      "Epoch 15/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4150 - accuracy: 0.8096 - val_loss: 0.5224 - val_accuracy: 0.7438\n",
      "Epoch 16/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4061 - accuracy: 0.8087 - val_loss: 0.5180 - val_accuracy: 0.7438\n",
      "Epoch 17/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8206 - val_loss: 0.5231 - val_accuracy: 0.7562\n",
      "Epoch 18/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.3957 - accuracy: 0.8170 - val_loss: 0.5202 - val_accuracy: 0.7512\n",
      "Epoch 19/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8198 - val_loss: 0.5328 - val_accuracy: 0.7612\n",
      "Epoch 20/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8217 - val_loss: 0.5373 - val_accuracy: 0.7488\n",
      "Epoch 21/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8237 - val_loss: 0.5309 - val_accuracy: 0.7687\n",
      "Epoch 22/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.3774 - accuracy: 0.8308 - val_loss: 0.5357 - val_accuracy: 0.7587\n",
      "Epoch 23/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8378 - val_loss: 0.5436 - val_accuracy: 0.7463\n",
      "Epoch 24/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3627 - accuracy: 0.8358 - val_loss: 0.5379 - val_accuracy: 0.7662\n",
      "Epoch 25/30\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.3575 - accuracy: 0.8438 - val_loss: 0.5481 - val_accuracy: 0.7687\n",
      "Epoch 26/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8460 - val_loss: 0.5616 - val_accuracy: 0.7562\n",
      "Epoch 27/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3521 - accuracy: 0.8400 - val_loss: 0.5873 - val_accuracy: 0.7463\n",
      "Epoch 28/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3438 - accuracy: 0.8474 - val_loss: 0.5592 - val_accuracy: 0.7488\n",
      "Epoch 29/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3377 - accuracy: 0.8474 - val_loss: 0.5535 - val_accuracy: 0.7612\n",
      "Epoch 30/30\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8513 - val_loss: 0.6222 - val_accuracy: 0.7189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd3db88f70>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#without country\n",
    "\n",
    "#normalize\n",
    "scaler = StandardScaler()\n",
    "urban_X_train_scaled = scaler.fit_transform(urban_X_train)\n",
    "urban_X_val_scaled = scaler.transform(urban_X_val)\n",
    "#urban_X_test_scaled = scaler.transform(urban_X_test)\n",
    "\n",
    "rural_X_train_scaled = scaler.fit_transform(rural_X_train)\n",
    "rural_X_val_scaled = scaler.fit_transform(rural_X_val)\n",
    "#rural_X_test_scaled = scalar.transform(rural_X_test)\n",
    "\n",
    "#convert labels\n",
    "urban_y_train_binary = (urban_y_train > 1.2).astype(int)\n",
    "urban_y_val_binary = (urban_y_val > 1.2).astype(int)\n",
    "#urban_y_test_binary = (urban_y_test > 1.2).astype(int)\n",
    "\n",
    "rural_y_train_binary = (rural_y_train > -0.5).astype(int)\n",
    "rural_y_val_binary = (rural_y_val > -0.5).astype(int)\n",
    "#rural_y_test_binary = (rural_y_test > -0.5).astype(int)\n",
    "\n",
    "#####make sure I change to rural or urban\n",
    "\n",
    "urban_model_cl = Sequential()\n",
    "urban_model_cl.add(Dense(64, activation='relu', input_shape=(41,)))\n",
    "urban_model_cl.add(Dense(32, activation='relu'))\n",
    "urban_model_cl.add(Dense(16, activation='relu'))\n",
    "urban_model_cl.add(Dense(1, activation='sigmoid'))\n",
    "urban_model_cl.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#train, predict\n",
    "urban_model_cl.fit(urban_X_train_scaled, urban_y_train_binary, batch_size=64, epochs=30, validation_data=(urban_X_val_scaled, urban_y_val_binary))\n",
    "#loss, accuracy = urban_model.evaluate(urban_X_test_scaled, urban_y_test_binary)\n",
    "#print(f\"Test Loss: {loss:.4f}\")\n",
    "#print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "#print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "CDuxSdcgV4cB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "103/103 [==============================] - 1s 3ms/step - loss: 0.6440 - accuracy: 0.6445 - val_loss: 0.6054 - val_accuracy: 0.6740\n",
      "Epoch 2/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.5877 - accuracy: 0.6981 - val_loss: 0.5845 - val_accuracy: 0.7070\n",
      "Epoch 3/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.7143 - val_loss: 0.5748 - val_accuracy: 0.7111\n",
      "Epoch 4/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.5427 - accuracy: 0.7265 - val_loss: 0.5761 - val_accuracy: 0.6988\n",
      "Epoch 5/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.5308 - accuracy: 0.7378 - val_loss: 0.5924 - val_accuracy: 0.7043\n",
      "Epoch 6/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.5191 - accuracy: 0.7442 - val_loss: 0.5640 - val_accuracy: 0.7153\n",
      "Epoch 7/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.7505 - val_loss: 0.5714 - val_accuracy: 0.7290\n",
      "Epoch 8/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.5005 - accuracy: 0.7566 - val_loss: 0.5664 - val_accuracy: 0.7180\n",
      "Epoch 9/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.7612 - val_loss: 0.5678 - val_accuracy: 0.7318\n",
      "Epoch 10/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.7665 - val_loss: 0.5552 - val_accuracy: 0.7400\n",
      "Epoch 11/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7685 - val_loss: 0.5642 - val_accuracy: 0.7208\n",
      "Epoch 12/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.7765 - val_loss: 0.5568 - val_accuracy: 0.7290\n",
      "Epoch 13/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7803 - val_loss: 0.5590 - val_accuracy: 0.7221\n",
      "Epoch 14/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.7742 - val_loss: 0.5754 - val_accuracy: 0.7221\n",
      "Epoch 15/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.7820 - val_loss: 0.5515 - val_accuracy: 0.7290\n",
      "Epoch 16/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4510 - accuracy: 0.7864 - val_loss: 0.5606 - val_accuracy: 0.7345\n",
      "Epoch 17/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.7896 - val_loss: 0.5647 - val_accuracy: 0.7345\n",
      "Epoch 18/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.7962 - val_loss: 0.5450 - val_accuracy: 0.7373\n",
      "Epoch 19/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4335 - accuracy: 0.7921 - val_loss: 0.5659 - val_accuracy: 0.7249\n",
      "Epoch 20/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.7965 - val_loss: 0.6025 - val_accuracy: 0.7373\n",
      "Epoch 21/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4227 - accuracy: 0.8068 - val_loss: 0.5695 - val_accuracy: 0.7359\n",
      "Epoch 22/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4226 - accuracy: 0.8022 - val_loss: 0.5753 - val_accuracy: 0.7208\n",
      "Epoch 23/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4138 - accuracy: 0.8089 - val_loss: 0.5859 - val_accuracy: 0.7263\n",
      "Epoch 24/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4104 - accuracy: 0.8098 - val_loss: 0.5868 - val_accuracy: 0.7276\n",
      "Epoch 25/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4079 - accuracy: 0.8069 - val_loss: 0.5655 - val_accuracy: 0.7414\n",
      "Epoch 26/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.4030 - accuracy: 0.8153 - val_loss: 0.6349 - val_accuracy: 0.7098\n",
      "Epoch 27/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.3991 - accuracy: 0.8164 - val_loss: 0.6205 - val_accuracy: 0.7249\n",
      "Epoch 28/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.3985 - accuracy: 0.8168 - val_loss: 0.6113 - val_accuracy: 0.7290\n",
      "Epoch 29/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.3918 - accuracy: 0.8211 - val_loss: 0.6180 - val_accuracy: 0.7249\n",
      "Epoch 30/30\n",
      "103/103 [==============================] - 0s 1ms/step - loss: 0.3915 - accuracy: 0.8198 - val_loss: 0.6184 - val_accuracy: 0.7235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd3de12940>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rural_model_cl = Sequential()\n",
    "rural_model_cl.add(Dense(64, activation='relu', input_shape=(41,)))\n",
    "rural_model_cl.add(Dense(32, activation='relu'))\n",
    "rural_model_cl.add(Dense(16, activation='relu'))\n",
    "rural_model_cl.add(Dense(1, activation='sigmoid'))\n",
    "rural_model_cl.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#train, predict\n",
    "rural_model_cl.fit(rural_X_train_scaled, rural_y_train_binary, batch_size=64, epochs=30, validation_data=(rural_X_val_scaled, rural_y_val_binary))\n",
    "#loss, accuracy = rural_model.evaluate(rural_X_test_scaled, rural_y_test_binary)\n",
    "#print(f\"Test Loss: {loss:.4f}\")\n",
    "#print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "#print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "yUGt7kVGCQd3"
   },
   "outputs": [],
   "source": [
    "#predictions = model.predict(urban_X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "Mx3oV6BCBw3F"
   },
   "outputs": [],
   "source": [
    "df_country = pd.read_csv('https://urldefense.com/v3/__https://raw.githubusercontent.com/SateeshKumar21/PovertyAnalysis/main/HW5/public_tables/country_test_reduct.csv__;!!Mih3wA!B14CyWPRDqkcCvQ7hvNsKmTyevDD2x1iJ_njKMCLQ_aOukCKCnrUvDbR4GD60DqBko1kwoXZpuW62l3mgyUz$ ', index_col=0)\n",
    "df_rand = pd.read_csv('https://urldefense.com/v3/__https://raw.githubusercontent.com/SateeshKumar21/PovertyAnalysis/main/HW5/public_tables/random_test_reduct.csv',index_col=0__;!!Mih3wA!B14CyWPRDqkcCvQ7hvNsKmTyevDD2x1iJ_njKMCLQ_aOukCKCnrUvDbR4GD60DqBko1kwoXZpuW62q4P8o0L$ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "BW53Nqlj--qz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 49.05574822425842 seconds\n",
      "0\n",
      "float type error: None\n",
      "length of file 4653\n"
     ]
    }
   ],
   "source": [
    "##### country test\n",
    "####replace df with df_test_country\n",
    "\n",
    "import time\n",
    "\n",
    "start_time=time.time()\n",
    "channel_values_lis = []\n",
    "\n",
    "floattypeerror=0\n",
    "# change the range to load more data, I picked 5000 bc that creates ~4.2 GiBs to download\n",
    "for n in range(len(df_country)):\n",
    "\n",
    "    row=df_country.iloc[n,:]\n",
    "    filename=row['filename']\n",
    "    urban=row['urban']\n",
    "    area ='urban' if urban else 'rural'\n",
    "    try:\n",
    "        M=load(path+'/'+filename)\n",
    "    except:\n",
    "        print (f'could not load image:{n}, path:'+path+\"/\"+filename)\n",
    "        continue\n",
    "    Image=M['x']\n",
    "    if np.max(Image) > 65_536:\n",
    "        print(\"above 16 byte size\")\n",
    "        channel_values_lis.append(Image)\n",
    "        floattypeerror+=1\n",
    "    elif np.max(Image) < -65_536:\n",
    "        print(\"below 16 byte size\")\n",
    "        channel_values_lis.append(Image)\n",
    "        floattypeerror+=1\n",
    "    else:\n",
    "        recast_arr = Image.astype(np.float16)\n",
    "        channel_values_lis.append(recast_arr)\n",
    "        \n",
    "\n",
    "end_time= time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(\"Execution time:\", execution_time,\"seconds\")\n",
    "print(\"float type error:\", print(floattypeerror))\n",
    "print(\"length of file\", len(channel_values_lis))\n",
    "# uncomment to cave file\n",
    "# np.save('channel_values_lis.npy', np.array(channel_values_lis))\n",
    "\n",
    "#mean\n",
    "for column in range(len(column_names)):\n",
    "    lis = []\n",
    "    for n in range(len(channel_values_lis)):\n",
    "        lis.append(channel_values_lis[n][column].mean())\n",
    "    df_country[column_names[column] + '_mean'] = lis\n",
    "\n",
    "#std\n",
    "for column in range(len(column_names)):\n",
    "    lis = []\n",
    "    for n in range(len(channel_values_lis)):\n",
    "        lis.append(np.std(channel_values_lis[n][column], dtype = np.float64))\n",
    "    df_country[column_names[column] + '_std'] = lis\n",
    "\n",
    "#median\n",
    "for column in range(len(column_names)):\n",
    "    lis = []\n",
    "    for n in range(len(channel_values_lis)):\n",
    "        lis.append(np.median(channel_values_lis[n][column]))\n",
    "    df_country[column_names[column] + '_median'] = lis\n",
    "\n",
    "#bright outliers\n",
    "for column in range(len(column_names)):\n",
    "    lis = []\n",
    "    for n in range(len(channel_values_lis)):\n",
    "        mean_col = column_names[column] + '_mean'\n",
    "        std_col = column_names[column] + '_std'\n",
    "        mean = df_country.iloc[n][mean_col]\n",
    "        std = df_country.iloc[n][std_col]\n",
    "        lis.append(np.count_nonzero(channel_values_lis[n][column] > (mean + 1.5 * std)))\n",
    "    df_country[column_names[column] + '_br_outlier'] = lis\n",
    "\n",
    "#dark outlier\n",
    "for column in range(len(column_names)):\n",
    "    lis = []\n",
    "    for n in range(len(channel_values_lis)):\n",
    "        mean_col = column_names[column] + '_mean'\n",
    "        std_col = column_names[column] + '_std'\n",
    "        mean = df_country.iloc[n][mean_col]\n",
    "        std = df_country.iloc[n][std_col]\n",
    "        lis.append(np.count_nonzero(channel_values_lis[n][column] < (mean - 1.5 * std)))\n",
    "    df_country[column_names[column] + '_dark_outlier'] = lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'country', 'urban', 'nl_mean', 'Red_mean', 'Green_mean',\n",
       "       'Blue_mean', 'NIR_mean', 'SWIR1_mean', 'SWIR2_mean', 'TEMP1_mean',\n",
       "       'NL_mean', 'Red_std', 'Green_std', 'Blue_std', 'NIR_std', 'SWIR1_std',\n",
       "       'SWIR2_std', 'TEMP1_std', 'NL_std', 'Red_median', 'Green_median',\n",
       "       'Blue_median', 'NIR_median', 'SWIR1_median', 'SWIR2_median',\n",
       "       'TEMP1_median', 'NL_median', 'Red_br_outlier', 'Green_br_outlier',\n",
       "       'Blue_br_outlier', 'NIR_br_outlier', 'SWIR1_br_outlier',\n",
       "       'SWIR2_br_outlier', 'TEMP1_br_outlier', 'NL_br_outlier',\n",
       "       'Red_dark_outlier', 'Green_dark_outlier', 'Blue_dark_outlier',\n",
       "       'NIR_dark_outlier', 'SWIR1_dark_outlier', 'SWIR2_dark_outlier',\n",
       "       'TEMP1_dark_outlier', 'NL_dark_outlier'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_country.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "jdTsEqAPJrB4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urban_df_features shape (1448, 43)\n",
      "rural_df_features shape (3205, 43)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\AppData\\Local\\Temp\\ipykernel_22788\\3718299548.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://urldefense.com/v3/__https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html*returning-a-view-versus-a-copy*5Cn__;IyU!!Mih3wA!B14CyWPRDqkcCvQ7hvNsKmTyevDD2x1iJ_njKMCLQ_aOukCKCnrUvDbR4GD60DqBko1kwoXZpuW62itULFX1$   rural_country_df.drop('country',axis=1,inplace=True)\n",
      "C:\\Users\\obaid\\AppData\\Local\\Temp\\ipykernel_22788\\3718299548.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://urldefense.com/v3/__https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html*returning-a-view-versus-a-copy*5Cn__;IyU!!Mih3wA!B14CyWPRDqkcCvQ7hvNsKmTyevDD2x1iJ_njKMCLQ_aOukCKCnrUvDbR4GD60DqBko1kwoXZpuW62itULFX1$   urban_country_df.drop('country',axis=1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "urban_country_df = df_country[df_country['urban']==True]\n",
    "rural_country_df = df_country[df_country['urban'] ==False]\n",
    "rural_country_df.drop('country',axis=1,inplace=True)\n",
    "urban_country_df.drop('country',axis=1,inplace=True)\n",
    "\n",
    "print(\"urban_df_features shape\", urban_country_df.shape)\n",
    "print(\"rural_df_features shape\", rural_country_df.shape)\n",
    "\n",
    "numeric_columns = rural_country_df.select_dtypes(include=np.number).columns\n",
    "\n",
    "rural_country = rural_country_df[numeric_columns]\n",
    "urban_country = urban_country_df[numeric_columns]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "urban_country_scaled = scaler.fit_transform(urban_country)\n",
    "rural_country_scaled = scaler.fit_transform(rural_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3205, 42)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rural_country.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "9xqCrOX5MIeq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 47.25349473953247 seconds\n",
      "0\n",
      "float type error: None\n",
      "length of file 4917\n"
     ]
    }
   ],
   "source": [
    "##### country test\n",
    "####replace df with df_test_rand\n",
    "\n",
    "import time\n",
    "\n",
    "start_time=time.time()\n",
    "channel_values_lis = []\n",
    "\n",
    "floattypeerror=0\n",
    "# change the range to load more data, I picked 5000 bc that creates ~4.2 GiBs to download\n",
    "for n in range(len(df_rand)):\n",
    "\n",
    "    row=df_rand.iloc[n,:]\n",
    "    filename=row['filename']\n",
    "    urban=row['urban']\n",
    "    area ='urban' if urban else 'rural'\n",
    "    try:\n",
    "        M=load(path+'/'+filename)\n",
    "    except:\n",
    "        print (f'could not load image:{n}, path:'+path+\"/\"+filename)\n",
    "        continue\n",
    "    Image=M['x']\n",
    "    if np.max(Image) > 65_536:\n",
    "        print(\"above 16 byte size\")\n",
    "        channel_values_lis.append(Image)\n",
    "        floattypeerror+=1\n",
    "    elif np.max(Image) < -65_536:\n",
    "        print(\"below 16 byte size\")\n",
    "        channel_values_lis.append(Image)\n",
    "        floattypeerror+=1\n",
    "    else:\n",
    "        recast_arr = Image.astype(np.float16)\n",
    "        channel_values_lis.append(recast_arr)\n",
    "        \n",
    "\n",
    "end_time= time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(\"Execution time:\", execution_time,\"seconds\")\n",
    "print(\"float type error:\", print(floattypeerror))\n",
    "print(\"length of file\", len(channel_values_lis))\n",
    "# uncomment to cave file\n",
    "# np.save('channel_values_lis.npy', np.array(channel_values_lis))\n",
    "\n",
    "#mean\n",
    "for column in range(len(column_names)):\n",
    "    lis = []\n",
    "    for n in range(len(channel_values_lis)):\n",
    "        lis.append(channel_values_lis[n][column].mean())\n",
    "    df_rand[column_names[column] + '_mean'] = lis\n",
    "\n",
    "#std\n",
    "for column in range(len(column_names)):\n",
    "    lis = []\n",
    "    for n in range(len(channel_values_lis)):\n",
    "        lis.append(np.std(channel_values_lis[n][column], dtype = np.float64))\n",
    "    df_rand[column_names[column] + '_std'] = lis\n",
    "\n",
    "#median\n",
    "for column in range(len(column_names)):\n",
    "    lis = []\n",
    "    for n in range(len(channel_values_lis)):\n",
    "        lis.append(np.median(channel_values_lis[n][column]))\n",
    "    df_rand[column_names[column] + '_median'] = lis\n",
    "\n",
    "#bright outliers\n",
    "for column in range(len(column_names)):\n",
    "    lis = []\n",
    "    for n in range(len(channel_values_lis)):\n",
    "        mean_col = column_names[column] + '_mean'\n",
    "        std_col = column_names[column] + '_std'\n",
    "        mean = df_rand.iloc[n][mean_col]\n",
    "        std = df_rand.iloc[n][std_col]\n",
    "        lis.append(np.count_nonzero(channel_values_lis[n][column] > (mean + 1.5 * std)))\n",
    "    df_rand[column_names[column] + '_br_outlier'] = lis\n",
    "\n",
    "#dark outlier\n",
    "for column in range(len(column_names)):\n",
    "    lis = []\n",
    "    for n in range(len(channel_values_lis)):\n",
    "        mean_col = column_names[column] + '_mean'\n",
    "        std_col = column_names[column] + '_std'\n",
    "        mean = df_rand.iloc[n][mean_col]\n",
    "        std = df_rand.iloc[n][std_col]\n",
    "        lis.append(np.count_nonzero(channel_values_lis[n][column] < (mean - 1.5 * std)))\n",
    "    df_rand[column_names[column] + '_dark_outlier'] = lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "hxr4Cv-GNnFO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urban_df_features shape (1707, 44)\n",
      "rural_df_features shape (3210, 44)\n"
     ]
    }
   ],
   "source": [
    "urban_rand_df = df_rand[df_rand['urban']==True]\n",
    "rural_rand_df = df_rand[df_rand['urban'] ==False]\n",
    "\n",
    "print(\"urban_df_features shape\", urban_rand_df.shape)\n",
    "print(\"rural_df_features shape\", rural_rand_df.shape)\n",
    "\n",
    "numeric_columns = rural_rand_df.select_dtypes(include=np.number).columns\n",
    "\n",
    "rural_rand = rural_rand_df[numeric_columns]\n",
    "urban_rand = urban_rand_df[numeric_columns]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "urban_rand_scaled = scaler.fit_transform(urban_rand)\n",
    "rural_rand_scaled = scaler.fit_transform(rural_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "1OyGZCWhOHw2",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 997us/step\n",
      "101/101 [==============================] - 0s 708us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\AppData\\Local\\Temp\\ipykernel_22788\\2378405921.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://urldefense.com/v3/__https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html*returning-a-view-versus-a-copy*5Cn__;IyU!!Mih3wA!B14CyWPRDqkcCvQ7hvNsKmTyevDD2x1iJ_njKMCLQ_aOukCKCnrUvDbR4GD60DqBko1kwoXZpuW62itULFX1$   urban_rand_df['preds_wo_abstention'] = urban_model.predict(urban_rand_scaled)\n",
      "C:\\Users\\obaid\\AppData\\Local\\Temp\\ipykernel_22788\\2378405921.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://urldefense.com/v3/__https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html*returning-a-view-versus-a-copy*5Cn__;IyU!!Mih3wA!B14CyWPRDqkcCvQ7hvNsKmTyevDD2x1iJ_njKMCLQ_aOukCKCnrUvDbR4GD60DqBko1kwoXZpuW62itULFX1$   rural_rand_df['preds_wo_abstention'] = rural_model.predict(rural_rand_scaled)\n"
     ]
    }
   ],
   "source": [
    "urban_rand_df['preds_wo_abstention'] = urban_model.predict(urban_rand_scaled)\n",
    "rural_rand_df['preds_wo_abstention'] = rural_model.predict(rural_rand_scaled)\n",
    "\n",
    "\n",
    "df_rand_final = pd.concat([urban_rand_df, rural_rand_df])\n",
    "df_rand_final.loc[df_rand_final['preds_wo_abstention']>=0.5,'pred_wo_abstention'] = int(1)\n",
    "\n",
    "df_rand_final.loc[df_rand_final['preds_wo_abstention']<0.5,'pred_wo_abstention'] = int(-1)\n",
    "\n",
    "\n",
    "df_rand_final = df_rand_final[['filename','urban','pred_wo_abstention']]\n",
    "df_rand_final['urban'] = df_rand_final['urban'].replace({True: 1, False: 0})\n",
    "#df_rand_final['pred_wo_abstention'] = df_rand_final['pred_wo_abstention'].replace({0:-1})\n",
    "\n",
    "df_rand_final.to_csv('results.csv')\n",
    "\n",
    "### need to concatenate then select correct columns\n",
    "\n",
    "#df_rand_final = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "KXfS3NWyJ7lJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 732us/step\n",
      "101/101 [==============================] - 0s 698us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\AppData\\Local\\Temp\\ipykernel_22788\\2106664636.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://urldefense.com/v3/__https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html*returning-a-view-versus-a-copy*5Cn__;IyU!!Mih3wA!B14CyWPRDqkcCvQ7hvNsKmTyevDD2x1iJ_njKMCLQ_aOukCKCnrUvDbR4GD60DqBko1kwoXZpuW62itULFX1$   urban_country_df['preds_with_abstention'] = urban_model_cl.predict(urban_country_scaled)\n",
      "C:\\Users\\obaid\\AppData\\Local\\Temp\\ipykernel_22788\\2106664636.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://urldefense.com/v3/__https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html*returning-a-view-versus-a-copy*5Cn__;IyU!!Mih3wA!B14CyWPRDqkcCvQ7hvNsKmTyevDD2x1iJ_njKMCLQ_aOukCKCnrUvDbR4GD60DqBko1kwoXZpuW62itULFX1$   rural_country_df['preds_with_abstention'] = rural_model_cl.predict(rural_country_scaled)\n"
     ]
    }
   ],
   "source": [
    "urban_country_df['preds_with_abstention'] = urban_model_cl.predict(urban_country_scaled)\n",
    "rural_country_df['preds_with_abstention'] = rural_model_cl.predict(rural_country_scaled)\n",
    "\n",
    "df_country_final = pd.concat([urban_country_df,rural_country_df])\n",
    "df_country_final.loc[df_country_final['preds_with_abstention']>=0.87,'pred_with_abstention'] = int(1)\n",
    "\n",
    "\n",
    "df_country_final.loc[df_country_final['preds_with_abstention'] <=0.13,'pred_with_abstention'] = int(-1)\n",
    "\n",
    "df_country_final.loc[((df_country_final['preds_with_abstention']<=0.87)&(df_country_final['preds_with_abstention']>=0.13)),'pred_with_abstention'] = int(0)\n",
    "\n",
    "df_country_final = df_country_final[['filename','urban','pred_with_abstention']]\n",
    "df_country_final['urban'] = df_country_final['urban'].replace({True:1, False: 0})\n",
    "\n",
    "#df_country_final['pred_with_abstention'] = df_country_final['pred_with_abstention'].replace({0:-1})\n",
    "\n",
    "df_country_final.to_csv('results_country.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
